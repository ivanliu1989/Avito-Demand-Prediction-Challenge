{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from collections import Counter\n",
    "import itertools \n",
    "import re\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### chargrams\n",
    "\n",
    "def char_ngrams(s):\n",
    "    result = Counter()\n",
    "    len_s = len(s)\n",
    "    for n in [3, 4, 5]:\n",
    "        result.update(s[i:i+n] for i in xrange(len_s - n + 1))\n",
    "    return result\n",
    "\n",
    "def compute_chargrams(batch_size=5000):\n",
    "    chargram_table = avito_utils.get_item_chargrams_table()\n",
    "    texts = avito_utils.select(avito_utils.item_info, ['title_clean', 'description_clean'], \n",
    "                                 batch_size=batch_size) \n",
    "    cnt = 1\n",
    "    processed = 0\n",
    "\n",
    "    for batch in texts:\n",
    "        t0 = time()\n",
    "        batch_result = []\n",
    "        for rec in tqdm(batch):\n",
    "            d = dict(_id=rec['_id'],\n",
    "                     chargram_title=char_ngrams(rec['title_clean'].replace(' ', '')),\n",
    "                     chargram_desc=char_ngrams(rec['description_clean'].replace(' ', '')))\n",
    "            batch_result.append(d)\n",
    "\n",
    "        chargram_table.insert_many(batch_result)\n",
    "        print('batch %d finished in %0.5fs' % (cnt, time() - t0)),\n",
    "\n",
    "        processed = processed + len(batch)\n",
    "        print('so far processed %d rows' % processed)\n",
    "        cnt = cnt + 1\n",
    "    \n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-a0b037b52a04>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-a0b037b52a04>\"\u001b[1;36m, line \u001b[1;32m23\u001b[0m\n\u001b[1;33m    text = re.sub(ur'(?<=[^а-я])(' + shortenings + ')[.]', ur'\\1 ', text)\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### NLP stuff\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer(result_type=None)\n",
    "from fastcache import clru_cache as lru_cache\n",
    "\n",
    "shortenings = [u'мм', u'см', u'м', u'км', u'мл', u'л', u'г', u'кг', u'т', u'лит',\n",
    "               u'р', u'руб', u'сот', u'га', u'шт', u'ш', u'дб', u'вт', \n",
    "               u'ул', u'пр', u'д', u'кв', u'чел', u'жен', u'муж', u'тыс', \n",
    "               u'др']\n",
    "\n",
    "shortenings = u'|'.join(shortenings)\n",
    "\n",
    "def remove_dots_from_shortenings(match):\n",
    "    s = match.string[match.start():match.end()]\n",
    "    return s.replace('.', '')\n",
    "\n",
    "def normalize(text):\n",
    "    text = text.lower().replace(u'ё', u'е')\n",
    "    text = text.replace(u'²', '2')\n",
    "    text = re.sub(r'(\\d+)[.](\\d+)', r'\\1,\\2', text)\n",
    "    text = re.sub(u'([a-zа-я][.]){2,}', remove_dots_from_shortenings, text)\n",
    "    text = re.sub(ur'(?<=[^а-я])(' + shortenings + ')[.]', ur'\\1 ', text)\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    #text = re.sub(r'(\\d+),(\\d+)', r'\\1.\\2', text)\n",
    "    text = re.sub(u'[^a-zа-я0-9.]', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def sentence_split(text):\n",
    "    text = normalize(text)\n",
    "    res = []\n",
    "    for s in re.split('[.!?;\\n]', text):\n",
    "        s = clean_text(s)\n",
    "        if s: \n",
    "            res.append(s)\n",
    "    return res\n",
    "\n",
    "def en_chars_cnt(s):\n",
    "    return sum(1 for c in s if u'a' <= c <= u'z')\n",
    "\n",
    "def ru_chars_cnt(s):\n",
    "    return sum(1 for c in s if u'а' <= c <= u'я')\n",
    "\n",
    "ru_en = {u'а': u'a', u'у': u'y', u'к': u'k', u'е': u'e', u'н': u'h', \n",
    "    u'г': u'r', u'х': u'x', u'в': u'b', u'а': u'a', u'р': u'p', \n",
    "    u'о': u'o', u'с': u'c', u'м': u'm', u'т': u't'}\n",
    "\n",
    "ru_translatable = set(ru_en.keys())\n",
    "en_translatable = set(ru_en.values())\n",
    "\n",
    "en_ru = {ord(v): k for k, v in ru_en.items()}\n",
    "ru_en = {ord(k): v for k, v in ru_en.items()}\n",
    "\n",
    "def translate(s):\n",
    "    # None - no need to translate\n",
    "    en_cnt = en_chars_cnt(s)\n",
    "    ru_cnt = ru_chars_cnt(s)\n",
    "    \n",
    "    if en_cnt == 0 or ru_cnt == 0:\n",
    "        return None\n",
    "   \n",
    "    if en_cnt > ru_cnt: \n",
    "        return s.translate(ru_en)\n",
    "    if ru_cnt > en_cnt:\n",
    "        return s.translate(en_ru)\n",
    "    \n",
    "    # en == ru\n",
    "    chars = set(s)\n",
    "    en_cnt = len(en_translatable & chars)\n",
    "    ru_cnt = len(ru_translatable & chars)\n",
    "    \n",
    "    if en_cnt > 0 and ru_cnt == 0:\n",
    "        return s.translate(en_ru)\n",
    "    if ru_cnt > 0 and en_cnt == 0:\n",
    "        return s.translate(ru_en)\n",
    "\n",
    "    # can't do anything here\n",
    "    return s\n",
    "\n",
    "def translate_tokens(sentence):\n",
    "    mixed = 0\n",
    "    result = []\n",
    "    for token in sentence.split():\n",
    "        trans = translate(token)\n",
    "        if trans is None:\n",
    "            result.append(token)\n",
    "        else:\n",
    "            result.append(trans)\n",
    "            mixed = mixed + 1\n",
    "    return ' '.join(result), mixed\n",
    "\n",
    "def is_digit(s):\n",
    "    if s.isdecimal():\n",
    "        return True\n",
    "    if re.match(ur'^\\d+[.]\\d+$', s):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def is_rus(s):\n",
    "    return ru_chars_cnt(s) == len(s)\n",
    "\n",
    "def is_eng(s):\n",
    "    return en_chars_cnt(s) == len(s)\n",
    "\n",
    "def is_rus_digit_mixed(s):\n",
    "    if re.match(ur'^[а-я0-9]+$', s):\n",
    "        return 0 < ru_chars_cnt(s) < len(s)\n",
    "    return False\n",
    "\n",
    "def is_eng_digit_mixed(s):\n",
    "    if re.match(ur'^[a-z0-9]+$', s):\n",
    "        return 0 < en_chars_cnt(s) < len(s)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
